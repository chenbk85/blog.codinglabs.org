{
    "articles": [
        {
            "id": "algorithms-for-cardinality-estimation-part-iv",
            "title": "解读Cardinality Estimation算法（第四部分：HyperLogLog Counting及Adaptive Counting）",
            "postedOn": "2013-01-09",
            "author": "张洋",
            "tags": [""],
            "abstract": "在前一篇文章中，我们了解了LogLog Counting。LLC算法的空间复杂度为\\(O(log_2(log_2(N_{max})))\\)，并且具有较高的精度，因此非常适合用于大数据场景的基数估计。不过LLC也有自己的问题，就是当基数不太大时，估计值的误差会比较大。这主要是因为当基数不太大时，可能存在一些空桶，这些空桶的\\(\\rho_{max}\\)为0。由于LLC的估计值依赖于各桶\\(\\rho_{max}\\)的几何平均数，而几何平均数对于特殊值（这里就是指0）非常敏感，因此当存在一些空桶时，LLC的估计效果就变得较差。"
        },
        {
            "id": "algorithms-for-cardinality-estimation-part-iii",
            "title": "解读Cardinality Estimation算法（第三部分：LogLog Counting）",
            "postedOn": "2013-01-03",
            "author": "张洋",
            "tags": [""],
            "abstract": "上一篇文章介绍的Linear Counting算法相较于直接映射bitmap的方法能大大节省内存（大约只需后者1/10的内存），但毕竟只是一个常系数级的降低，空间复杂度仍然为\\(O(N_{max})\\)。而本文要介绍的LogLog Counting却只有\\(O(log_2(log_2(N_{max})))\\)。例如，假设基数的上限为1亿，原始bitmap方法需要12.5M内存，而LogLog Counting只需不到1K内存（640字节）就可以在标准误差不超过4%的精度下对基数进行估计，效果可谓十分惊人。"
        },
        {
            "id": "algorithms-for-cardinality-estimation-part-ii",
            "title": "解读Cardinality Estimation算法（第二部分：Linear Counting）",
            "postedOn": "2012-12-31",
            "author": "张洋",
            "tags": [""],
            "abstract": "在上一篇文章中，我们知道传统的精确基数计数算法在数据量大时会存在一定瓶颈，瓶颈主要来自于数据结构合并和内存使用两个方面。因此出现了很多基数估计的概率算法，这些算法虽然计算出的结果不是精确的，但误差可控，重要的是这些算法所使用的数据结构易于合并，同时比传统方法大大节省内存。"
        },
        {
            "id": "algorithms-for-cardinality-estimation-part-i",
            "title": "解读Cardinality Estimation算法（第一部分：基本概念）",
            "postedOn": "2012-12-30",
            "author": "张洋",
            "tags": [""],
            "abstract": "作为“解读Cardinality Estimation算法”系列文章的第一部分，本文将首先介绍基数的概念，然后通过一个电商数据分析的例子说明基数如何在具体业务场景中发挥作用以及为什么在大数据面前基数的计算是困难的，在这一部分也同时会详述传统基数计数的解决方案及遇到的难题。后面在第二部分-第四部分会分别详细介绍Linear Counting、LogLog Counting、HyperLogLog Counting及Adaptive Counting四个算法，会涉及算法的基本思路、概率分析及论文关键部分的解读。最后在第五部分会介绍一淘数据部的开源基数估计算法库ccard-lib，这个算法库由一淘数据部工程师清无（王晓哲）、民瞻（张维）及我开发，并已用于一淘数据部多个业务线，ccard-lib实现了上述四种算法，整个库使用C写成，并附带PHP扩展模块，我会在这一部分介绍ccard-lib的实现重点及使用方法。"
        },
        {
            "id": "cardinality-estimation",
            "title": "基数估计算法概览",
            "postedOn": "2012-11-23",
            "author": "张洋",
            "tags": [""],
            "abstract": "翻译自《Damn Cool Algorithms: Cardinality Estimation》，原文链接：http://blog.notdot.net/2012/09/Dam-Cool-Algorithms-Cardinality-Estimation"
        },
        {
            "id": "hash-collisions-attack-on-php",
            "title": "PHP哈希表碰撞攻击原理",
            "postedOn": "2012-01-04",
            "author": "张洋",
            "tags": [""],
            "abstract": "最近哈希表碰撞攻击（Hashtable collisions as DOS attack）的话题不断被提起，各种语言纷纷中招。本文结合PHP内核源码，聊一聊这种攻击的原理及实现。"
        },
        {
            "id": "theory-of-mysql-index",
            "title": "MySQL索引背后的数据结构及算法原理",
            "postedOn": "2011-10-18",
            "author": "张洋",
            "tags": [""],
            "abstract": "本文以MySQL数据库为研究对象，讨论与数据库索引相关的一些话题。特别需要说明的是，MySQL支持诸多存储引擎，而各种存储引擎对索引的支持也各不相同，因此MySQL数据库支持多种索引类型，如BTree索引，哈希索引，全文索引等等。为了避免混乱，本文将只关注于BTree索引，因为这是平常使用MySQL时主要打交道的索引，至于哈希索引和全文索引本文暂不讨论。"
        }
    ]
}
